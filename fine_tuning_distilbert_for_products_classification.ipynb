{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMni95n5T23l41KCyRLAnHZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["### Installing and importing the required modules"],"metadata":{"id":"ZAbMjkhsSyq-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"sh1Mxz3wD9cI"},"outputs":[],"source":["!pip install torch transformers accelerate bitsandbytes datasets evaluate\n","!pip install -U bitsandbytes"]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","import pandas as pd\n","from evaluate import load\n","from typing import Dict, Any\n","from datasets import Dataset\n","from google.colab import drive\n","from huggingface_hub import login\n","from google.colab import userdata\n","from sklearn.preprocessing import LabelEncoder\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, BitsAndBytesConfig, TrainingArguments, Trainer"],"metadata":{"id":"QV9rVdkGEFFI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Setting up the environment"],"metadata":{"id":"ewOtjy0DNz52"}},{"cell_type":"code","source":["# Mounting the drive\n","drive.mount('/content/drive')"],"metadata":{"id":"d9E_WHBeNwl9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Constants, hyperparameters and model configurations"],"metadata":{"id":"BlHtrAS4G_3c"}},{"cell_type":"code","source":["seed = 42 # Seed for reproducibility\n","test_size = 0.2 # Train-test split percentage\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # The device to run the model on\n","model_id = \"distilbert-base-uncased\" # The model ID of the Llama model\n","dataset_path = \"/content/drive/MyDrive/Colab Notebooks/FineTuningLLM/datasets/iphone_products.csv\" # The path to the dataset\n","model_path = \"/content/drive/MyDrive/Colab Notebooks/FineTuningLLM/saved_models/iphone_products_classifier\" # Path to save the trained model to"],"metadata":{"id":"_OMAcVUtEWyv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Print the detected device\n","print(f\"Detected device: {device}\")"],"metadata":{"id":"E5A58TsXOdcF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Data loading"],"metadata":{"id":"iJtYT9AAJA9Z"}},{"cell_type":"code","source":["# Load the dataset into a pandas DataFrame\n","dataset = pd.read_csv(\n","    dataset_path,\n","    delimiter = \",\",\n","    on_bad_lines = \"skip\"  # Skip problematic lines if necessary\n",")"],"metadata":{"id":"UGd3OTw_JChU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Drop null values\n","dataset.dropna(inplace=True)"],"metadata":{"id":"0FREMlY2hd7m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Show a subset of the samples\n","dataset.head()"],"metadata":{"id":"obTlSyEdJSyN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Tokenizer"],"metadata":{"id":"6YwNOg1CHqJp"}},{"cell_type":"code","source":["# Load the tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(model_id, paddind_side=\"left\")"],"metadata":{"id":"FDgHdDxaEa5k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Preprocess data"],"metadata":{"id":"VWe7YFh9KM47"}},{"cell_type":"code","source":["# Concatenate the product and its title\n","dataset[\"summary\"] = dataset[\"product\"] + \" - \" + dataset[\"title\"]"],"metadata":{"id":"jEzN8p-vhFmp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Instantiate  the label encoder\n","label_encoder = LabelEncoder()\n","\n","# Encode the target column (category_description) into numeric labels\n","dataset.loc[:, \"label\"] = label_encoder.fit_transform(dataset[\"label\"])\n","\n","# Extract and print the total number of classes\n","num_classes = len(label_encoder.classes_)\n","print(f\"Total number of classes: {num_classes}\")"],"metadata":{"id":"bU876oPwJ0WS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert the Pandas DataFrame to a Hugging Face Dataset\n","hf_dataset = Dataset.from_pandas(dataset)\n","\n","# Train-test split\n","train_dataset, test_dataset = hf_dataset.train_test_split(test_size=test_size, seed=seed).values()"],"metadata":{"id":"FYydkXj3KxYe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Preprocess the dataset\n","def preprocess(examples: Dict[str, Any], max_length: int = 48) -> Dict[str, Any]:\n","    # Tokenize the input sequences\n","    return tokenizer(\n","        examples[\"summary\"],\n","        truncation = True,\n","        padding = \"max_length\",\n","        max_length = max_length\n","    )\n","\n","# Tokenize the dataset\n","tokenized_train_dataset = train_dataset.map(preprocess, batched=True)\n","tokenized_test_dataset = test_dataset.map(preprocess, batched=True)\n","\n","# Remove unnecessary columns\n","tokenized_train_dataset = tokenized_train_dataset.remove_columns([\"product\", \"title\"])\n","tokenized_test_dataset = tokenized_test_dataset.remove_columns([\"product\", \"title\"])\n","\n","# Display the sequence length\n","print(f\"Sequence length: {len(tokenized_train_dataset[0]['input_ids'])}\")"],"metadata":{"id":"Eh7bXTEOMEbn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Building the model"],"metadata":{"id":"8jVoBtk0HwS9"}},{"cell_type":"markdown","source":[],"metadata":{"id":"QKZhzQNvHssF"}},{"cell_type":"code","source":["# Load the model\n","model = AutoModelForSequenceClassification.from_pretrained(\n","    model_id,\n","    num_labels = num_classes\n",")"],"metadata":{"id":"BGRRZ6OvE8Ro"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Move the model to the taret device\n","model.to(device);"],"metadata":{"id":"GOimK-VDZJzd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Display the model\n","model"],"metadata":{"id":"yBQ4ApsxlRL_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Trainig the model"],"metadata":{"id":"ddnJy6u3IILa"}},{"cell_type":"code","source":["# Load the accuracy metric\n","accuracy_metric = load(\"accuracy\")\n","\n","# Define a custum function to compute the metrics\n","def compute_metrics(eval_pred: torch.Tensor) -> torch.Tensor:\n","    # Extract the logits and the lables from the output of the model\n","    logits, labels = eval_pred\n","\n","    # Extract the predictions for each sample\n","    predictions = np.argmax(logits, axis=-1)\n","\n","    # Compute and return the accuarcy\n","    return accuracy_metric.compute(predictions=predictions, references=labels)"],"metadata":{"id":"RJa1Dkv4NRT6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the training arguments\n","training_args = TrainingArguments(\n","    output_dir = \"./iphone_products_classifier\",\n","    eval_strategy = \"epoch\",\n","    save_strategy = \"epoch\",\n","    learning_rate = 3e-4,\n","    per_device_train_batch_size = 8,\n","    per_device_eval_batch_size = 8,\n","    num_train_epochs = 20,\n","    weight_decay = 0.01,\n","    logging_dir = \"./logs\",\n","    logging_strategy = \"steps\",\n","    logging_steps = 10,\n","    save_total_limit = 2,\n","    load_best_model_at_end = True,\n","    metric_for_best_model = \"accuracy\",\n","    greater_is_better = True,\n","    report_to = \"none\",\n","    fp16 = True\n",")"],"metadata":{"id":"n6IqtdVEIJ46"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Instantiate the trainer to train the model\n","trainer = Trainer(\n","    model = model,\n","    args = training_args,\n","    train_dataset = tokenized_train_dataset,\n","    eval_dataset = tokenized_test_dataset,\n","    compute_metrics = compute_metrics\n",")\n","\n","# Trainin the model\n","trainer.train()"],"metadata":{"id":"PX8Id63uNJ0D"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Save the model"],"metadata":{"id":"NXKZO4iY6j5V"}},{"cell_type":"code","source":["# Saving the adapter to the destination path\n","model.save_pretrained(model_path)"],"metadata":{"id":"IG859UBQ6n_L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Load the fine-tuned model"],"metadata":{"id":"wKGMC3q08t6o"}},{"cell_type":"code","source":["# Define the quantization configurations of the model (only for CUDA devices)\n","quantization_config = BitsAndBytesConfig(\n","    load_in_4bit = True,\n","    bnb_4bit_quant_type = 'nf4',\n","    bnb_4bit_compute_dtype = torch.bfloat16,\n","    bnb_4bit_use_double_quant = True\n",")"],"metadata":{"id":"iE2oJ42U9BYa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the fine-tuned model\n","model = AutoModelForSequenceClassification.from_pretrained(\n","    model_path,\n","    low_cpu_mem_usage = True,\n","    quantization_config = quantization_config\n",")"],"metadata":{"id":"CGEk88YD838p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Move the fine-tuned model to the target device\n","model.to(device);"],"metadata":{"id":"3UYNc3xkkjTc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Inference"],"metadata":{"id":"YI9Bm9SoDEOS"}},{"cell_type":"code","source":["# Tokenize a sample input\n","inputs = tokenizer(\n","    [\n","        \"Iphone 12 pro 256 danneggiato\", # 1\n","        \"Cover antigraffio per iPhone\", # 0\n","        \"Drone per iphone con custodia\", # 0\n","        \"iPhone 13 mini 500TB Rosa\", # 1\n","        \"Set di pellicole per iphone 15 pro max\" # 0\n","    ],\n","    padding = True,\n","    truncation = True,\n","    return_tensors=\"pt\"\n","  ).to(device)"],"metadata":{"id":"etrKOfCGD0GR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Perform inference\n","with torch.no_grad():\n","    # Compute the output of the model\n","    outputs = model(**inputs)\n","\n","    # Extract the predictions\n","    predictions = torch.argmax(outputs.logits, dim=-1)\n","\n","# Convert the predictions to a numpy array\n","predictions = predictions.cpu().numpy()\n","\n","# Convert the predicted labels to the corresponding categories\n","predicted_categories = label_encoder.inverse_transform(predictions)"],"metadata":{"id":"cdWiC7QUDDK1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Display the predicted categories\n","for idx, predicted_category in enumerate(predicted_categories):\n","    print(f\"Sample {idx + 1} --> Predicted label: {predictions[idx]} | Predicted Category: {predicted_category}\")"],"metadata":{"id":"u7UQeY7aD22a"},"execution_count":null,"outputs":[]}]}
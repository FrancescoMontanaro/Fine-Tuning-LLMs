{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZAbMjkhsSyq-"
   },
   "source": [
    "### Installing and importing the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "QV9rVdkGEFFI"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from evaluate import load\n",
    "from datasets import Dataset\n",
    "from typing import Dict, Any\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import AutoTokenizer, BitsAndBytesConfig, AutoModelForSequenceClassification, TrainingArguments, Trainer, EvalPrediction\n",
    "\n",
    "# Add the parent directory to the system path\n",
    "sys.path.append(str(Path().resolve().parent))\n",
    "\n",
    "# Import local dependencies\n",
    "from src.utils import get_device, set_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlHtrAS4G_3c"
   },
   "source": [
    "### Constants, hyperparameters and model configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_OMAcVUtEWyv"
   },
   "outputs": [],
   "source": [
    "seed = 42 # Seed for reproducibility\n",
    "test_size = 0.2 # Train-test split percentage\n",
    "validation_size = 0.1 # Train-validation split percentage\n",
    "model_id = \"bert-base-uncased\" # The model ID of the Llama model\n",
    "dataset_path = Path().resolve().parent.parent / \"datasets\" / \"iphone_products.csv\" # Path to the dataset\n",
    "model_path = Path().resolve().parent.parent / \"saved_models\" / \"iphone_products_classifier\" # Path to save the trained model to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for reproducibility\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "E5A58TsXOdcF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected device: mps\n"
     ]
    }
   ],
   "source": [
    "# Get the device available on the system\n",
    "device = get_device()\n",
    "\n",
    "# Print the detected device\n",
    "print(f\"Detected device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJtYT9AAJA9Z"
   },
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "UGd3OTw_JChU"
   },
   "outputs": [],
   "source": [
    "# Load the dataset into a pandas DataFrame\n",
    "dataset = pd.read_csv(\n",
    "    dataset_path,\n",
    "    delimiter = \",\",\n",
    "    on_bad_lines = \"skip\"  # Skip problematic lines if necessary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0FREMlY2hd7m"
   },
   "outputs": [],
   "source": [
    "# Basic cleanup\n",
    "dataset = dataset.dropna(subset=[\"product\", \"title\", \"label\"]).copy()\n",
    "dataset[\"product\"] = dataset[\"product\"].astype(str)\n",
    "dataset[\"title\"] = dataset[\"title\"].astype(str)\n",
    "dataset[\"label\"] = dataset[\"label\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "obTlSyEdJSyN"
   },
   "outputs": [],
   "source": [
    "# Show a subset of the samples\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6YwNOg1CHqJp"
   },
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FDgHdDxaEa5k"
   },
   "outputs": [],
   "source": [
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, padding_side=\"right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VWe7YFh9KM47"
   },
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jEzN8p-vhFmp"
   },
   "outputs": [],
   "source": [
    "# Concatenate the product and its title\n",
    "dataset[\"summary\"] = dataset[\"product\"] + \" - \" + dataset[\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bU876oPwJ0WS"
   },
   "outputs": [],
   "source": [
    "# Instantiate  the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode the target column (category_description) into numeric labels\n",
    "dataset[\"labels\"] = label_encoder.fit_transform(dataset[\"label\"])\n",
    "dataset[\"labels\"] = dataset[\"labels\"].astype(\"int64\")\n",
    "\n",
    "# Extract and print the total number of classes\n",
    "num_classes = len(label_encoder.classes_)\n",
    "print(f\"Total number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FYydkXj3KxYe"
   },
   "outputs": [],
   "source": [
    "# Convert the Pandas DataFrame to a Hugging Face Dataset\n",
    "hf_dataset = Dataset.from_pandas(dataset)\n",
    "\n",
    "# Train-valid-test split\n",
    "train_dataset, test_dataset = hf_dataset.train_test_split(test_size=test_size, seed=seed).values()\n",
    "train_dataset, valid_dataset = train_dataset.train_test_split(test_size=validation_size, seed=seed).values()\n",
    "\n",
    "# Print the number of training and test samples\n",
    "print(f\"Number of training samples: {len(train_dataset)}\")\n",
    "print(f\"Number of validation samples: {len(valid_dataset)}\")\n",
    "print(f\"Number of test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eh7bXTEOMEbn"
   },
   "outputs": [],
   "source": [
    "# Preprocess the dataset\n",
    "def preprocess(examples: Dict[str, Any], max_length: int = 48) -> Dict[str, Any]:\n",
    "    # Tokenize the input sequences\n",
    "    return tokenizer(\n",
    "        examples[\"summary\"],\n",
    "        truncation = True,\n",
    "        padding = \"max_length\",\n",
    "        max_length = max_length\n",
    "    )\n",
    "    \n",
    "# Apply the preprocessing to the datasets\n",
    "tokenized_train = train_dataset.map(preprocess, batched=True, remove_columns=[\"product\", \"title\", \"label\", \"summary\"])\n",
    "tokenized_valid = valid_dataset.map(preprocess, batched=True, remove_columns=[\"product\", \"title\", \"label\", \"summary\"])\n",
    "tokenized_test = test_dataset.map(preprocess, batched=True, remove_columns=[\"product\", \"title\", \"label\", \"summary\"])\n",
    "\n",
    "# Confirm sequence length\n",
    "print(f\"Sequence length: {len(tokenized_train[0]['input_ids'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8jVoBtk0HwS9"
   },
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BGRRZ6OvE8Ro"
   },
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_id,\n",
    "    num_labels = num_classes\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yBQ4ApsxlRL_"
   },
   "outputs": [],
   "source": [
    "# Display the model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the number of parameters in the model\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters in the model: {total_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddnJy6u3IILa"
   },
   "source": [
    "### Trainig the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RJa1Dkv4NRT6"
   },
   "outputs": [],
   "source": [
    "# Load the accuracy metric\n",
    "accuracy_metric = load(\"accuracy\")\n",
    "\n",
    "# Define the compute_metrics function\n",
    "def compute_metrics(eval_pred: EvalPrediction) -> Dict[str, float]:\n",
    "    # Extract the logits and labels from the EvalPrediction object\n",
    "    logits = eval_pred.predictions\n",
    "    labels = eval_pred.label_ids\n",
    "    \n",
    "    # Handle the case where logits is a tuple\n",
    "    if isinstance(logits, tuple):\n",
    "        logits = logits[0]\n",
    "        \n",
    "    # Get the predicted class labels and compute the accuracy\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    out = accuracy_metric.compute(predictions=preds, references=labels)\n",
    "    \n",
    "    # Safety check\n",
    "    assert out is not None, \"Metrics computation failed.\"\n",
    "    \n",
    "    # Convert all metric values to float\n",
    "    return {k: float(v) for k, v in out.items()}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n6IqtdVEIJ46"
   },
   "outputs": [],
   "source": [
    "# Mixed precision settings\n",
    "use_cuda = torch.cuda.is_available() and \"cuda\" in str(device).lower()\n",
    "use_pin_memory = bool(use_cuda)\n",
    "bf16 = bool(use_cuda and torch.cuda.is_bf16_supported())\n",
    "\n",
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = \"./checkpoints/iphone_products_classifier\",\n",
    "    eval_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate = 3e-5,\n",
    "    per_device_train_batch_size = 16,\n",
    "    per_device_eval_batch_size = 16,\n",
    "    num_train_epochs = 10,\n",
    "    weight_decay = 0.01,\n",
    "    logging_dir = \"./logs\",\n",
    "    logging_strategy = \"steps\",\n",
    "    logging_steps = 50,\n",
    "    save_total_limit = 2,\n",
    "    load_best_model_at_end = True,\n",
    "    metric_for_best_model = \"eval_accuracy\",\n",
    "    greater_is_better = True,\n",
    "    report_to = \"none\",\n",
    "    dataloader_pin_memory = use_pin_memory,\n",
    "    bf16 = bf16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PX8Id63uNJ0D"
   },
   "outputs": [],
   "source": [
    "# Instantiate the trainer to train the model\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = tokenized_train,\n",
    "    eval_dataset = tokenized_valid,\n",
    "    compute_metrics = compute_metrics\n",
    ")\n",
    "\n",
    "# Training the model\n",
    "trainer_output = trainer.train()\n",
    "\n",
    "# Pretty print the training results\n",
    "print(trainer_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXKZO4iY6j5V"
   },
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IG859UBQ6n_L"
   },
   "outputs": [],
   "source": [
    "# Saving the adapter to the destination path\n",
    "model.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wKGMC3q08t6o"
   },
   "source": [
    "### Load the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear GPU cache\n",
    "if torch.cuda.is_available():\n",
    "\ttorch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iE2oJ42U9BYa"
   },
   "outputs": [],
   "source": [
    "# Define the quantization configurations of the model (only for CUDA devices)\n",
    "quantization_config = None\n",
    "if use_cuda:\n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit = True,\n",
    "        bnb_4bit_quant_type = \"nf4\",\n",
    "        bnb_4bit_compute_dtype = torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16,\n",
    "        bnb_4bit_use_double_quant = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CGEk88YD838p"
   },
   "outputs": [],
   "source": [
    "# Reload the fine-tuned model \n",
    "reload_kwargs = {}\n",
    "if quantization_config is not None:\n",
    "    reload_kwargs.update(dict(quantization_config=quantization_config, device_map=\"auto\"))\n",
    "\n",
    "# Reload the fine-tuned model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_path,\n",
    "    **reload_kwargs\n",
    ").to(device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "predictions = []\n",
    "\n",
    "# Iterate over the test dataset in batches\n",
    "for i in range(0, len(tokenized_test), training_args.per_device_eval_batch_size):\n",
    "    # Prepare the batch\n",
    "    batch = tokenized_test[i : i + training_args.per_device_eval_batch_size]\n",
    "    inputs = {k: torch.tensor(v).to(device) for k, v in batch.items() if k not in [\"labels\", \"__index_level_0__\"]}\n",
    "    \n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        # Predict the outputs\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "    # Extract the predictions\n",
    "    logits = outputs.logits\n",
    "    preds = logits.argmax(dim=-1)\n",
    "    \n",
    "    # Append the predictions to the list\n",
    "    predictions.extend(preds.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display metrics\n",
    "eval_metrics = accuracy_metric.compute(predictions=predictions, references=tokenized_test[\"labels\"])\n",
    "\n",
    "# Display the test accuracy\n",
    "assert eval_metrics is not None, \"Evaluation metrics are not available.\"\n",
    "print(f\"Test Accuracy: {eval_metrics['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YI9Bm9SoDEOS"
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "etrKOfCGD0GR"
   },
   "outputs": [],
   "source": [
    "# Inference on sample inputs\n",
    "inference_inputs = [\n",
    "        \"Iphone 12 pro 256 danneggiato\", # 1\n",
    "        \"Cover antigraffio per iPhone\", # 0\n",
    "        \"Drone per iphone con custodia\", # 0\n",
    "        \"iPhone 13 mini 500TB Rosa\", # 1\n",
    "        \"Set di pellicole per iphone 15 pro max\" # 0\n",
    "]\n",
    "\n",
    "# Tokenize a sample input\n",
    "inputs = tokenizer(\n",
    "    inference_inputs,\n",
    "    padding = True,\n",
    "    truncation = True,\n",
    "    return_tensors=\"pt\"\n",
    "  ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cdWiC7QUDDK1"
   },
   "outputs": [],
   "source": [
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    # Compute the output of the model\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # Extract the predictions\n",
    "    predictions = torch.argmax(outputs.logits, dim=-1).cpu().numpy()\n",
    "\n",
    "# Convert the predicted labels to the corresponding categories\n",
    "predicted_categories = label_encoder.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u7UQeY7aD22a"
   },
   "outputs": [],
   "source": [
    "# Display the predicted categories\n",
    "for idx, (inference_input, predicted_category) in enumerate(zip(inference_inputs, predicted_categories)):\n",
    "    print(f\"Sample {idx + 1} --> Input: {inference_input} | Predicted label: {predictions[idx]} | Predicted Category: {predicted_category}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMni95n5T23l41KCyRLAnHZ",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
